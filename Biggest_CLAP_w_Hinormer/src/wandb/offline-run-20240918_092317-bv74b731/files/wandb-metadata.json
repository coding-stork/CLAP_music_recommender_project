{
  "os": "Linux-6.1.85+-x86_64-with-glibc2.35",
  "python": "3.10.12",
  "startedAt": "2024-09-18T09:23:17.544031Z",
  "args": [
    "--save-frequency",
    "5",
    "--save-top-performance",
    "3",
    "--save-most-recent",
    "--dataset-type=webdataset",
    "--precision=fp32",
    "--batch-size=4",
    "--lr=1e-4",
    "--wd=0.0",
    "--epochs=45",
    "--workers=2",
    "--use-bn-sync",
    "--amodel",
    "HTSAT-tiny",
    "--tmodel",
    "roberta",
    "--warmup",
    "3200",
    "--report-to",
    "wandb",
    "--wandb-notes",
    "10.16-clap-dataset-1#-htsat-roberta",
    "--datasetnames",
    "spotify_train",
    "audiocaps",
    "--datasetinfos",
    "train",
    "unbalanced_train",
    "--top-k-checkpoint-select-dataset=Clotho-test",
    "--top-k-checkpoint-select-metric=mAP@10",
    "--openai-model-cache-dir",
    "/content/transformers_cache",
    "--seed",
    "3407",
    "--datasetpath",
    "/content",
    "--gather-with-grad",
    "--optimizer",
    "adam",
    "--data-filling",
    "repeatpad",
    "--data-truncating",
    "rand_trunc",
    "--pretrained-audio",
    "/content/audio_pretrained_model/HTSAT-fullset-imagenet-map=0.467.ckpt"
  ],
  "program": "/content/drive/MyDrive/CLAP/src/laion_clap/training/main.py",
  "codePath": "src/laion_clap/training/main.py",
  "git": {
    "remote": "https://github.com/LAION-AI/CLAP.git",
    "commit": "8e558817d853808486768004fa1b61ac9d69f2a2"
  },
  "root": "/content/drive/MyDrive/CLAP/src",
  "host": "a29ba2c38aca",
  "username": "root",
  "executable": "/usr/bin/python3",
  "codePathLocal": "laion_clap/training/main.py"
}