{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6ho6MkzL7WW"
      },
      "source": [
        "# LOAD ALL FILES FROM FILES_FOR_DEFINITIVE_TEST_CLAP_EMBEDDINGS IN /CONTENT/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoN-GBcfI5h5",
        "outputId": "03a1e223-b4b5-4196-8b7e-11fb68c2b6f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.26.4\n"
          ]
        }
      ],
      "source": [
        "# CHECK THAT THE NUMPY VERSION IS 1.26.4\n",
        "\n",
        "import numpy as np\n",
        "print(np.__version__)\n",
        "\n",
        "#otherwise install it\n",
        "#!pip install --force-reinstall numpy==1.26.4\n",
        "\n",
        "#note - the results vary if a more recent version of numpy is utilized instead of that used during the project development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download the required files and dictionaries (you can use gdown or any library you prefer)\n",
        "\n",
        "-> https://drive.google.com/file/d/1hvXfqOrVL1igzMOe31soZ46SnVjm5rg-/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "djcFfIjE5Jk4"
      },
      "outputs": [],
      "source": [
        "#@markdown #LOADING FILES\n",
        "\n",
        "import pickle\n",
        "total_nodes = []\n",
        "all_hinormer_node_embeddings = {}\n",
        "all_hinormer_audio_embeddings = {}\n",
        "all_relphormer_node_embeddings = {}\n",
        "all_relphormer_audio_embeddings = {}\n",
        "all_relphormer_vanilla_node_embeddings = {}\n",
        "\n",
        "with open('/content/biggest_hinormer_total_nodes.pkl', 'rb') as f:\n",
        "    total_nodes = pickle.load(f)\n",
        "\n",
        "with open('/content/relphormer_biggest_all_node_embeddings_v2.pkl', 'rb') as f:\n",
        "    all_relphormer_node_embeddings = pickle.load(f)\n",
        "\n",
        "with open('/content/relphormer_biggest_all_audio_embeddings_v2.pkl', 'rb') as f:\n",
        "    all_relphormer_audio_embeddings = pickle.load(f)\n",
        "\n",
        "with open('/content/hinormer_biggest_all_node_embeddings.pkl', 'rb') as f:\n",
        "    all_hinormer_node_embeddings = pickle.load(f)\n",
        "\n",
        "with open('/content/hinormer_biggest_all_audio_embeddings.pkl', 'rb') as f:\n",
        "    all_hinormer_audio_embeddings = pickle.load(f)\n",
        "\n",
        "with open('/content/relphormer_biggest_vanilla_all_node_embeddings.pkl', 'rb') as f:\n",
        "    all_relphormer_vanilla_node_embeddings = pickle.load(f)\n",
        "\n",
        "import pickle\n",
        "biggest_degree_centrality_for_uri = {}\n",
        "biggest_pagerank_for_uri = {}\n",
        "biggest_uri_to_popularity = {}\n",
        "\n",
        "with open('/content/biggest_degree_centrality_for_uri.pkl', 'rb') as f:\n",
        "    biggest_degree_centrality_for_uri = pickle.load(f)\n",
        "\n",
        "with open('/content/biggest_pagerank_for_uri.pkl', 'rb') as f:\n",
        "    biggest_pagerank_for_uri = pickle.load(f)\n",
        "\n",
        "with open('/content/biggest_uri_to_popularity.pkl', 'rb') as f:\n",
        "    biggest_uri_to_popularity = pickle.load(f)\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "with open('/content/old_id_to_new_id.pkl', 'rb') as f:\n",
        "    old_id_to_new_id = pickle.load(f)\n",
        "\n",
        "with open('/content/new_id_to_old_id.pkl', 'rb') as f:\n",
        "    new_id_to_old_id = pickle.load(f)\n",
        "\n",
        "with open('/content/old_uri_to_new_id.pkl', 'rb') as f:\n",
        "    old_uri_to_new_id = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OSLzJ7Am52h0"
      },
      "outputs": [],
      "source": [
        "#@markdown #DEFINE THE FETCH_RECOMMENDATIONS FUNCTION\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "Number_of_Recommendations_per_Model = 100 #@param {type:\"number\"}\n",
        "\n",
        "def find_top_10_audio(node_tensor, all_audio_embeddings):\n",
        "\n",
        "    audio_keys = list(all_audio_embeddings.keys())\n",
        "    audio_embeddings = np.stack([all_audio_embeddings[key] for key in audio_keys])\n",
        "    similarities = cosine_similarity(audio_embeddings, [node_tensor]) #does cosine similarity with all the embeddings of the opposite media\n",
        "    top_10_indices = np.argsort(np.squeeze(similarities, axis=1))[-Number_of_Recommendations_per_Model:][::-1]\n",
        "    top_10_audio_keys = [audio_keys[idx] for idx in top_10_indices]\n",
        "    return top_10_audio_keys, np.squeeze(similarities, axis=1)[top_10_indices]\n",
        "\n",
        "def find_top_10_nodes(audio_tensor, all_node_embeddings):\n",
        "\n",
        "    node_keys = list(all_node_embeddings.keys())\n",
        "    node_embeddings = np.stack([all_node_embeddings[key] for key in node_keys])\n",
        "    similarities = cosine_similarity(node_embeddings, [audio_tensor])\n",
        "    top_10_indices = np.argsort(np.squeeze(similarities, axis=1))[-(5*Number_of_Recommendations_per_Model):][::-1]\n",
        "    top_10_node_keys = [node_keys[idx] for idx in top_10_indices]\n",
        "    return top_10_node_keys, np.squeeze(similarities, axis=1)[top_10_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gQe9CX2a59tp"
      },
      "outputs": [],
      "source": [
        "#@markdown #CREATE LISTS AND DICTIONARIES\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "orig_tracks_dataset = pd.read_csv(\"/content/nva_final_tracks_less.csv\")\n",
        "new_tracks_dataset = pd.read_csv(\"/content/more_tracks_less_modified.csv\")\n",
        "tracks_dataset = orig_tracks_dataset.merge(new_tracks_dataset,how=\"outer\")\n",
        "playlists_dataset = pd.read_csv(\"/content/final_playlists.csv\")\n",
        "artists_dataset = pd.read_csv(\"/content/artists.csv\")\n",
        "nomi_tracce = tracks_dataset['name'].values\n",
        "data_tracce = tracks_dataset['release_date'].values\n",
        "uri_tracce = tracks_dataset['track_uri'].values\n",
        "track_indexes_for_playlists = {}\n",
        "track_indexes_for_artists = {}\n",
        "total_artists = []\n",
        "total_playlists = []\n",
        "total_titles = []\n",
        "\n",
        "for i, row in tracks_dataset.iterrows():\n",
        "  nome_traccia = row['name']\n",
        "  nome_artisti = row['artists_names']\n",
        "  playlist_uris = row['playlist_uris']\n",
        "  nome_artisti = nome_artisti.strip('][').strip(\"'\").strip('\"').split(\"', '\")\n",
        "\n",
        "  for k in nome_artisti:\n",
        "    if k not in track_indexes_for_artists:\n",
        "      track_indexes_for_artists[k] = []\n",
        "      total_artists.append(k)\n",
        "    track_indexes_for_artists[k].append(i)\n",
        "\n",
        "  nome_artisti = \", \".join(nome_artisti)\n",
        "  playlist_uris = playlist_uris.strip('][').strip(\"'\").split(\"', '\")\n",
        "  total_titles.append(nome_artisti+\" - \"+nome_traccia)\n",
        "\n",
        "old_track_uris = orig_tracks_dataset['track_uri']\n",
        "new_track_uris = new_tracks_dataset['track_uri']\n",
        "\n",
        "orig_order_track_uris = list(np.concatenate((old_track_uris,new_track_uris))) #crea una lista con l'ordine corretto degli audio files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PXiwfgyON0zv"
      },
      "outputs": [],
      "source": [
        "#@markdown #MAIN FUNCTION FOR INDEX REBALANCING\n",
        "\n",
        "import numpy as np\n",
        "from itertools import islice\n",
        "\n",
        "\n",
        "def remove_duplicates(audio_tracks, probability_indexes): #remove duplicate files (mostly used on audio2node coz of the 5 equal embeddings for each node -> 0_1, 0_2, 0_3... have the same node embedding)\n",
        "    unique_entries = {}\n",
        "\n",
        "    for track, prob in zip(audio_tracks, probability_indexes):\n",
        "        prefix = track.split('_')[0]\n",
        "\n",
        "        if (prefix, prob) not in unique_entries:\n",
        "            unique_entries[(prefix, prob)] = track\n",
        "\n",
        "    final_audio_tracks = np.array(list(unique_entries.values()))\n",
        "    final_probability_indexes = np.array([key[1] for key in unique_entries.keys()])\n",
        "\n",
        "    return final_audio_tracks, final_probability_indexes\n",
        "\n",
        "\n",
        "def normalize_and_weight_similarity(indexes, search_type):\n",
        "    min_val = np.min(indexes)\n",
        "    max_val = np.max(indexes)\n",
        "    normalized_indexes = (indexes - min_val) / (max_val - min_val + 1e-8) #map to interval 0-1\n",
        "\n",
        "    mapped_indexes = 0.7 * normalized_indexes + 0.3\n",
        "\n",
        "    return mapped_indexes\n",
        "\n",
        "def process_and_normalize_results(temp_audio_results, search_type):\n",
        "    results_keys = np.array(list(temp_audio_results.keys()))\n",
        "    results_scores = np.array(list(temp_audio_results.values()))\n",
        "    normalized_scores = normalize_and_weight_similarity(results_scores, search_type)\n",
        "    normalized_results = {key: score for key, score in zip(results_keys, normalized_scores)}\n",
        "    return normalized_results\n",
        "\n",
        "\n",
        "def find_similarities(new_num, search_type, embeddings_1, embeddings_2, all_similarities_dictionary, displaytext, top_results_dictionaries):\n",
        "  # search types can be: relphormer_node, hinormer_node, relphormer_audio, hinormer_audio or node_to_node\n",
        "\n",
        "  int_new_num = int(new_num[:-7])\n",
        "\n",
        "  temp_audio_results = {}\n",
        "  current_top_results_keys = []\n",
        "  current_top_results_scores = []\n",
        "\n",
        "  if search_type == \"relphormer_node\" or search_type == \"hinormer_node\":\n",
        "\n",
        "    raw_temp_audio_results = {}\n",
        "\n",
        "    for h in range(5):\n",
        "      results, indexes = find_top_10_nodes(embeddings_1[new_num[:-7]+\"_\"+str(h)],embeddings_2)\n",
        "      results, indexes = remove_duplicates(results, indexes)\n",
        "\n",
        "      for ix,i in enumerate(results):\n",
        "\n",
        "        if i in raw_temp_audio_results.keys():\n",
        "          raw_temp_audio_results[i] = raw_temp_audio_results[i] + indexes[ix]\n",
        "        else:\n",
        "          raw_temp_audio_results[i] = indexes[ix]\n",
        "\n",
        "        if ix < 100: #this limit is to avoid people putting numbers too high because the performance gets a lot worse, you can override\n",
        "          current_top_results_keys.append(i)\n",
        "          current_top_results_scores.append(indexes[ix])\n",
        "\n",
        "    temp_audio_results = process_and_normalize_results(raw_temp_audio_results, search_type)\n",
        "\n",
        "    sorted_audio_results = {k: v for k, v in sorted(temp_audio_results.items(), key=lambda x: x[1], reverse=True)}\n",
        "\n",
        "    for k,v in sorted_audio_results.items():\n",
        "\n",
        "      if k in all_similarities_dictionary.keys():\n",
        "            all_similarities_dictionary[k] = all_similarities_dictionary[k] + v\n",
        "      else:\n",
        "          all_similarities_dictionary[k] = v\n",
        "\n",
        "\n",
        "  elif search_type == \"relphormer_audio\" or search_type == \"hinormer_audio\":\n",
        "    results, indexes = find_top_10_audio(embeddings_1[new_num[:-5]],embeddings_2)\n",
        "    results, indexes = remove_duplicates(results, indexes)\n",
        "    indexes = normalize_and_weight_similarity(indexes, search_type)\n",
        "\n",
        "    for ix,i in enumerate(results):\n",
        "\n",
        "      if i in all_similarities_dictionary.keys():\n",
        "\n",
        "        all_similarities_dictionary[i] = all_similarities_dictionary[i] + indexes[ix]\n",
        "      else:\n",
        "        all_similarities_dictionary[i] = indexes[ix]\n",
        "\n",
        "      if ix < 100:\n",
        "        current_top_results_keys.append(i)\n",
        "        current_top_results_scores.append(indexes[ix])\n",
        "\n",
        "  elif search_type == \"node_to_node\": # relphormer node to node comparison\n",
        "\n",
        "    results, indexes = find_top_10_nodes(embeddings_1[new_num[:-5]],embeddings_2)\n",
        "    results, indexes = remove_duplicates(results, indexes)\n",
        "\n",
        "    indexes = indexes / 2 #this one is naturally weighted down a bit\n",
        "\n",
        "    for ix,i in enumerate(results):\n",
        "\n",
        "\n",
        "      if i in all_similarities_dictionary.keys():\n",
        "        all_similarities_dictionary[i] = all_similarities_dictionary[i] + indexes[ix]\n",
        "      else:\n",
        "        all_similarities_dictionary[i] = indexes[ix]\n",
        "\n",
        "      if ix < 100:\n",
        "        current_top_results_keys.append(i)\n",
        "        current_top_results_scores.append(indexes[ix])\n",
        "\n",
        "  else: print(\"search type unknown\")\n",
        "\n",
        "  #print(f\"original {displaytext} results: \\n\\n,{results}\") #they are wrong anyway\n",
        "\n",
        "  top_results_dictionaries[search_type] = {\"keys\": current_top_results_keys, \"scores\": current_top_results_scores}\n",
        "\n",
        "  return all_similarities_dictionary, top_results_dictionaries\n",
        "\n",
        "def find_similar_tracks(input_file):\n",
        "\n",
        "  all_similarities_dictionary = {}\n",
        "  top_results_dictionaries = {}\n",
        "\n",
        "  #do all 5 different embedding comparison tasks\n",
        "  all_similarities_dictionary, top_results_dictionaries = find_similarities(input_file, \"relphormer_audio\", all_relphormer_node_embeddings, all_relphormer_audio_embeddings, all_similarities_dictionary, \"relphormer node to audio\", top_results_dictionaries)\n",
        "  all_similarities_dictionary, top_results_dictionaries = find_similarities(input_file, \"relphormer_node\", all_relphormer_audio_embeddings, all_relphormer_node_embeddings, all_similarities_dictionary, \"relphormer audio to nodes\", top_results_dictionaries)\n",
        "  all_similarities_dictionary, top_results_dictionaries = find_similarities(input_file, \"hinormer_audio\", all_hinormer_node_embeddings, all_hinormer_audio_embeddings, all_similarities_dictionary, \"hinormer node to audio\", top_results_dictionaries)\n",
        "  all_similarities_dictionary, top_results_dictionaries = find_similarities(input_file, \"hinormer_node\", all_hinormer_audio_embeddings, all_hinormer_node_embeddings, all_similarities_dictionary, \"hinormer audio to nodes\", top_results_dictionaries)\n",
        "  all_similarities_dictionary, top_results_dictionaries = find_similarities(input_file, \"node_to_node\", all_relphormer_vanilla_node_embeddings, all_relphormer_vanilla_node_embeddings, all_similarities_dictionary, \"relphoremer vanilla node to node\", top_results_dictionaries)\n",
        "\n",
        "  final_weighted_similarities = {}\n",
        "  for track_key, initial_score in all_similarities_dictionary.items():\n",
        "      num_appearances = 0\n",
        "      position_bias = 0.0\n",
        "      for search_type in top_results_dictionaries:\n",
        "          if track_key in top_results_dictionaries[search_type][\"keys\"]:\n",
        "              num_appearances += 1\n",
        "              rank = top_results_dictionaries[search_type][\"keys\"].index(track_key) + 1\n",
        "\n",
        "      if num_appearances > 1: #if a song appears more than once, it should get a small boost\n",
        "          for search_type in top_results_dictionaries:\n",
        "              if track_key in top_results_dictionaries[search_type][\"keys\"]:\n",
        "                  rank = top_results_dictionaries[search_type][\"keys\"].index(track_key) + 1\n",
        "                  position_bias += 0.3 * np.exp(-0.1 * (rank - 1)) #calculate position bias (the higher the track appears on multiple models, the more is relevant)\n",
        "\n",
        "      base_weight = 1.0 if num_appearances > 1 else 0.7 #weight down if appears once\n",
        "      weighted_score = initial_score * base_weight * (num_appearances / 2.0 if num_appearances > 0 else 0.5) + position_bias #custom made formula (quite random)\n",
        "      final_weighted_similarities[track_key] = weighted_score\n",
        "\n",
        "\n",
        "  print(\"\\n\\n\\n\",total_titles[old_uri_to_new_id[orig_order_track_uris[int(input_file[:-7])]]])\n",
        "  print(old_uri_to_new_id[orig_order_track_uris[int(input_file[:-7])]])\n",
        "\n",
        "  print(\"\\n\\n\\n\\n DICTIONARY SORTED SIMILARITIES: \\n\\n\\n\\n\")\n",
        "  sorted_similarities = {k: v for k, v in sorted(final_weighted_similarities.items(), key=lambda x: x[1], reverse=True)}\n",
        "  for k,v in islice(sorted_similarities.items(),30):\n",
        "    print(total_titles[old_uri_to_new_id[orig_order_track_uris[int(k[:-2])]]])\n",
        "    print(\"weighted similarity: \",v)\n",
        "    print(\"degree centrality: \",biggest_degree_centrality_for_uri[orig_order_track_uris[int(k[:-2])]])\n",
        "    print(\"pagerank value: \",biggest_pagerank_for_uri[orig_order_track_uris[int(k[:-2])]])\n",
        "    print(\"spotify popularity: \",biggest_uri_to_popularity[orig_order_track_uris[int(k[:-2])]])\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz7lnvJMOhbC",
        "outputId": "53a29d29-b819-4a30-92fd-b04534e023d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Michael Jackson - Bad (feat. Pitbull)  :  14318\n",
            "Michael Jackson - Man In The Mirror  :  12683\n",
            "Michael Jackson - Off the Wall  :  19275\n",
            "Michael Jackson - The Way You Make Me Feel - Single Version  :  9146\n",
            "Michael Jackson - Bad  :  16905\n",
            "Michael Jackson - Get on the Floor  :  15161\n"
          ]
        }
      ],
      "source": [
        "#@markdown #HERE YOU CAN FIND THE INDEX OF A TRACK IN THE DATASET\n",
        "\n",
        "term_to_search = 'Michael Jackson' #@param {type:\"string\"}\n",
        "\n",
        "search_mask = tracks_dataset.apply(lambda row: row.astype(str).str.contains(term_to_search).any(), axis=1)\n",
        "search_results = tracks_dataset.loc[search_mask]\n",
        "results_uris = search_results['track_uri']\n",
        "\n",
        "result_indexes = [old_uri_to_new_id[uri] for uri in results_uris]\n",
        "actual_result_indexes = [new_id_to_old_id[index] for index in result_indexes]\n",
        "for ix,i in enumerate(result_indexes):\n",
        "  if actual_result_indexes[ix] > 8000: #<8000 = training set\n",
        "    print(total_titles[i],\" : \",actual_result_indexes[ix])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhcTeO3WNCXQ",
        "outputId": "79983f10-c8b7-4283-edfa-ca70d9711795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " Michael Jackson - Bad\n",
            "17562\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " DICTIONARY SORTED SIMILARITIES: \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bobby O - I'm So Hot for You\n",
            "weighted similarity:  3.093314280228493\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  1.4481481475143374e-05\n",
            "spotify popularity:  25\n",
            "\n",
            "\n",
            "\n",
            "Amii Stewart - Knock On Wood\n",
            "weighted similarity:  2.861776188776239\n",
            "degree centrality:  0.0001324298673494162\n",
            "pagerank value:  1.5130926346385888e-05\n",
            "spotify popularity:  54\n",
            "\n",
            "\n",
            "\n",
            "McFadden & Whitehead - Ain't No Stoppin' Us Now\n",
            "weighted similarity:  2.6837823448833404\n",
            "degree centrality:  0.00017657315646588828\n",
            "pagerank value:  1.5970628831414143e-05\n",
            "spotify popularity:  54\n",
            "\n",
            "\n",
            "\n",
            "McFadden & Whitehead - Ain't No Stoppin' Us Now\n",
            "weighted similarity:  2.5894402929776152\n",
            "degree centrality:  0.00017657315646588828\n",
            "pagerank value:  1.5970628831414143e-05\n",
            "spotify popularity:  54\n",
            "\n",
            "\n",
            "\n",
            "Michael Jackson - Get on the Floor\n",
            "weighted similarity:  2.4808794130706966\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  1.1019558962637868e-05\n",
            "spotify popularity:  50\n",
            "\n",
            "\n",
            "\n",
            "Michael Jackson - Bad\n",
            "weighted similarity:  2.432659550797164\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  9.100574744867534e-06\n",
            "spotify popularity:  0\n",
            "\n",
            "\n",
            "\n",
            "Michael Jackson - Bad\n",
            "weighted similarity:  2.3963332597899507\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  9.100574744867534e-06\n",
            "spotify popularity:  0\n",
            "\n",
            "\n",
            "\n",
            "Barry White - You're The First, The Last, My Everything - Single Version\n",
            "weighted similarity:  2.1740830447844934\n",
            "degree centrality:  0.00022071644558236035\n",
            "pagerank value:  2.1503762176865397e-05\n",
            "spotify popularity:  69\n",
            "\n",
            "\n",
            "\n",
            "MC Hammer - U Can't Touch This\n",
            "weighted similarity:  1.9974941743379429\n",
            "degree centrality:  0.0008387224932129694\n",
            "pagerank value:  6.93773275652173e-05\n",
            "spotify popularity:  72\n",
            "\n",
            "\n",
            "\n",
            "Michael Jackson - Bad\n",
            "weighted similarity:  1.9638869360495719\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  9.100574744867534e-06\n",
            "spotify popularity:  0\n",
            "\n",
            "\n",
            "\n",
            "Sinitta - So Macho\n",
            "weighted similarity:  1.9064412887768718\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  1.1590583328348375e-05\n",
            "spotify popularity:  33\n",
            "\n",
            "\n",
            "\n",
            "Patrick Cowley - Menergy\n",
            "weighted similarity:  1.8479552148596574\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  1.3224008602774665e-05\n",
            "spotify popularity:  39\n",
            "\n",
            "\n",
            "\n",
            "Bobby O - I'm So Hot for You\n",
            "weighted similarity:  1.8333758749767262\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  1.4481481475143374e-05\n",
            "spotify popularity:  25\n",
            "\n",
            "\n",
            "\n",
            "Kylie Minogue - I Should Be So Lucky\n",
            "weighted similarity:  1.8257427128511887\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  1.0052545343630711e-05\n",
            "spotify popularity:  55\n",
            "\n",
            "\n",
            "\n",
            "Quincy Jones - Ai No Corrida\n",
            "weighted similarity:  1.6657192026646717\n",
            "degree centrality:  0.0002648597346988324\n",
            "pagerank value:  2.6855987939573607e-05\n",
            "spotify popularity:  55\n",
            "\n",
            "\n",
            "\n",
            "Michael Jackson - Off the Wall\n",
            "weighted similarity:  1.5934893992921544\n",
            "degree centrality:  0.00017657315646588828\n",
            "pagerank value:  1.6575879997286036e-05\n",
            "spotify popularity:  65\n",
            "\n",
            "\n",
            "\n",
            "The Blow Monkeys - Digging Your Scene\n",
            "weighted similarity:  1.5578234960618214\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  8.4069053906804e-06\n",
            "spotify popularity:  30\n",
            "\n",
            "\n",
            "\n",
            "Michael Jackson - Bad (feat. Pitbull)\n",
            "weighted similarity:  1.537162057506941\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  8.868182896968657e-06\n",
            "spotify popularity:  40\n",
            "\n",
            "\n",
            "\n",
            "Boy George - Time (Clock Of The Heart)\n",
            "weighted similarity:  1.528741471471729\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  9.995666296654178e-06\n",
            "spotify popularity:  33\n",
            "\n",
            "\n",
            "\n",
            "Michael Jackson - Get on the Floor\n",
            "weighted similarity:  1.5159506184006832\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  1.1019558962637868e-05\n",
            "spotify popularity:  50\n",
            "\n",
            "\n",
            "\n",
            "Quincy Jones - Ai No Corrida\n",
            "weighted similarity:  1.4215639889332272\n",
            "degree centrality:  0.0002648597346988324\n",
            "pagerank value:  2.6855987939573607e-05\n",
            "spotify popularity:  55\n",
            "\n",
            "\n",
            "\n",
            "Benny Benassi, The Biz - Satisfaction - Isak Original Extended\n",
            "weighted similarity:  1.4198073950631167\n",
            "degree centrality:  0.00017657315646588828\n",
            "pagerank value:  1.813019903236795e-05\n",
            "spotify popularity:  64\n",
            "\n",
            "\n",
            "\n",
            "Michael Jackson - Off the Wall\n",
            "weighted similarity:  1.405471606497729\n",
            "degree centrality:  0.00017657315646588828\n",
            "pagerank value:  1.6575879997286036e-05\n",
            "spotify popularity:  65\n",
            "\n",
            "\n",
            "\n",
            "Patrice Rushen - Haven't You Heard - 12\" Version\n",
            "weighted similarity:  1.3766264698792818\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  1.1095499094426972e-05\n",
            "spotify popularity:  31\n",
            "\n",
            "\n",
            "\n",
            "Mr. Mister - Broken Wings - Single Version\n",
            "weighted similarity:  1.3533883409001524\n",
            "degree centrality:  0.00017657315646588828\n",
            "pagerank value:  1.6427440781821494e-05\n",
            "spotify popularity:  52\n",
            "\n",
            "\n",
            "\n",
            "The Shapeshifters - Oh What A Night\n",
            "weighted similarity:  1.3492683353277097\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  1.319046801473093e-05\n",
            "spotify popularity:  2\n",
            "\n",
            "\n",
            "\n",
            "Michael Jackson - The Way You Make Me Feel - Single Version\n",
            "weighted similarity:  1.2710923437517638\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  9.100574744867534e-06\n",
            "spotify popularity:  0\n",
            "\n",
            "\n",
            "\n",
            "Sheila E. - Koo Koo\n",
            "weighted similarity:  1.2682000225368724\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  1.1283687720488672e-05\n",
            "spotify popularity:  26\n",
            "\n",
            "\n",
            "\n",
            "Jonas Brothers - Pom Poms\n",
            "weighted similarity:  1.21793685130871\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  9.764998313800918e-06\n",
            "spotify popularity:  43\n",
            "\n",
            "\n",
            "\n",
            "Michael Jackson - Bad\n",
            "weighted similarity:  1.2158329761045354\n",
            "degree centrality:  8.828657823294414e-05\n",
            "pagerank value:  9.100574744867534e-06\n",
            "spotify popularity:  0\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@markdown #INSERT THE TRACK INDEX TO OBTAIN RECOMMENDATIONS\n",
        "\n",
        "index_to_process = \"16905\" #@param {type:\"string\"}\n",
        "\n",
        "find_similar_tracks(index_to_process+\"_0.flac\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
